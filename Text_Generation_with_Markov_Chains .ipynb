{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üìò Text Generation With Markov Chains\n",
        "\n",
        "This project implements a **Markov Chain based Text Generator** using **n-gram language modeling**.  \n",
        "It demonstrates how a machine can \"babble\" text by learning how often tokens (words or characters) follow each other.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "VG00G2SPnj3H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîπ Environment & Configuration\n",
        "We first import required libraries, fix randomness for reproducibility, and set **key configuration parameters**:\n",
        "\n",
        "- `LEVEL`: `'word'` or `'char'`  \n",
        "- `ORDER`: N-gram order (context size = ORDER-1)  \n",
        "- `GENERATE_LEN`: How many tokens to generate  \n",
        "- `SEED_TEXT`: Optional starting phrase  \n",
        "- `HOLDOUT_FRACTION`: Fraction of dataset reserved for evaluation\n"
      ],
      "metadata": {
        "id": "_XBNmeA8p7OD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pjZRceXqhCX",
        "outputId": "9f7e8e81-9117-4fbf-d03d-0c7b5004ef20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Environment Ready\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import re\n",
        "import math\n",
        "import json\n",
        "from collections import defaultdict, Counter\n",
        "from google.colab import files\n",
        "\n",
        "# For reproducibility\n",
        "random.seed(42)\n",
        "print(\"‚úÖ Environment Ready\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LEVEL = 'word'\n",
        "ORDER = 3\n",
        "GENERATE_LEN = 120\n",
        "SEED_TEXT = ''\n",
        "HOLDOUT_FRACTION = 0.1\n",
        "\n",
        "assert LEVEL in {'word', 'char'}, \"LEVEL must be 'word' or 'char'\"\n",
        "assert ORDER >= 2, \"ORDER must be >= 2\"\n",
        "\n",
        "print(f\"üìå LEVEL={LEVEL}, ORDER={ORDER}, GENERATE_LEN={GENERATE_LEN}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbn8wYI5q9oj",
        "outputId": "c6de4ea0-7c14-496c-9442-fb7c96847ae7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìå LEVEL=word, ORDER=3, GENERATE_LEN=120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîπ Dataset Upload / Sample Fallback\n",
        "We upload a `.txt` dataset. If no file is uploaded, we use a fallback story.  \n",
        "\n",
        "- Run the cell ‚Üí upload a file  \n",
        "- Output shows the file name and character count  \n"
      ],
      "metadata": {
        "id": "WMshraQbqGl4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_text_from_upload():\n",
        "    print(\"üí° Upload a .txt file\")\n",
        "    uploaded = files.upload()\n",
        "    if not uploaded:\n",
        "        return None, None\n",
        "    fname = next(iter(uploaded.keys()))\n",
        "    with open(fname, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "        text = f.read()\n",
        "    return fname, text\n",
        "\n",
        "SAMPLE_TEXT = (\n",
        "    \"Once upon a time, in a land far away, there lived a curious student who loved to build models. \"\n",
        "    \"They read books, collected stories, and stitched together patterns of words. \"\n",
        "    \"One day, they discovered that by counting how often words follow other words, \"\n",
        "    \"they could teach a machine to babble convincingly. \"\n",
        "    \"Markov chains, simple yet powerful, became their favorite tool.\"\n",
        ")\n",
        "\n",
        "try:\n",
        "    fname, raw_text = load_text_from_upload()\n",
        "except Exception as e:\n",
        "    print(\"No file uploaded:\", e)\n",
        "    fname, raw_text = None, None\n",
        "\n",
        "if not raw_text:\n",
        "    fname = \"sample.txt\"\n",
        "    raw_text = SAMPLE_TEXT\n",
        "\n",
        "print(f\"üìÑ Loaded: {fname} | {len(raw_text):,} characters\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "8jCusghRrGkB",
        "outputId": "381339cd-dfb7-4e22-e110-e0021f3532fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üí° Upload a .txt file\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9da1dcd7-539d-4693-9bdb-f9cfa2425380\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9da1dcd7-539d-4693-9bdb-f9cfa2425380\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving alternate_sample_corpus.txt to alternate_sample_corpus.txt\n",
            "üìÑ Loaded: alternate_sample_corpus.txt | 366 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîπ Tokenization & Data Split\n",
        "We **tokenize** the text into smaller units (words or characters) and split into **training** and **holdout** sets.\n",
        "\n",
        "- Word-level tokenizer extracts words & punctuation  \n",
        "- Char-level tokenizer splits text into characters  \n"
      ],
      "metadata": {
        "id": "ZD3qSdYwpVeD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_word_tokenize(text):\n",
        "    return re.findall(r\"[A-Za-z0-9']+|[.!?,;:\\-\\n]\", text.lower())\n",
        "\n",
        "def char_tokenize(text):\n",
        "    return list(text)\n",
        "\n",
        "if LEVEL == 'word':\n",
        "    tokens = simple_word_tokenize(raw_text)\n",
        "else:\n",
        "    tokens = char_tokenize(raw_text)\n",
        "\n",
        "print(f\"üîπ {len(tokens):,} tokens\")\n",
        "print(\"Sample:\", tokens[:20])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-ybSDWRu4TZ",
        "outputId": "2b361316-ec0e-4a53-fbd0-f99bcea05d3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ 78 tokens\n",
            "Sample: ['\\n', 'once', 'upon', 'a', 'time', ',', 'in', 'a', 'land', 'far', 'away', ',', 'there', 'lived', 'a', 'curious', 'student', 'who', 'loved', 'to']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split = int(len(tokens) * (1 - HOLDOUT_FRACTION))\n",
        "train_tokens = tokens[:split]\n",
        "holdout_tokens = tokens[split:]\n",
        "print(f\"Train: {len(train_tokens):,}, Holdout: {len(holdout_tokens):,}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCDQ76qLvEfJ",
        "outputId": "4ff9dad2-d577-4de7-a5e4-7d0f27e8d2e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 70, Holdout: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîπ Build the N-gram Model\n",
        "We build a **context ‚Üí next token counter**.  \n",
        "\n",
        "- For `ORDER=3`, context = 2 tokens ‚Üí predicts the 3rd.  \n",
        "- Stored in a dictionary of Counters.  "
      ],
      "metadata": {
        "id": "KKyMj4Byo3wY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_ngram_model(tokens, order):\n",
        "    context_counts = defaultdict(Counter)\n",
        "    for i in range(len(tokens) - order + 1):\n",
        "        context = tuple(tokens[i:i+order-1])\n",
        "        nxt = tokens[i+order-1]\n",
        "        context_counts[context][nxt] += 1\n",
        "    return context_counts\n",
        "\n",
        "context_counts = build_ngram_model(train_tokens, ORDER)\n",
        "print(f\"üìä Unique contexts: {len(context_counts):,}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0S2eqHGvOK0",
        "outputId": "358ac0d4-d43e-4c51-dd5d-c540174f9c68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Unique contexts: 65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîπ Text Generation\n",
        "We generate text by:\n",
        "1. Picking a starting context (from seed or random).  \n",
        "2. Sampling next tokens based on learned probabilities.  \n",
        "3. Repeating for `GENERATE_LEN` tokens.  \n"
      ],
      "metadata": {
        "id": "YZC4yTsupF_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pick_next(counter):\n",
        "    total = sum(counter.values())\n",
        "    r = random.uniform(0, total)\n",
        "    upto = 0\n",
        "    for tok, cnt in counter.items():\n",
        "        upto += cnt\n",
        "        if upto >= r:\n",
        "            return tok\n",
        "    return random.choice(list(counter.keys()))\n",
        "\n",
        "def choose_start_context(tokens, order, seed_text=''):\n",
        "    if seed_text:\n",
        "        seed_toks = simple_word_tokenize(seed_text) if LEVEL == 'word' else list(seed_text)\n",
        "        if len(seed_toks) >= order - 1:\n",
        "            return tuple(seed_toks[-(order-1):])\n",
        "    start_idx = random.randint(0, len(tokens) - order)\n",
        "    return tuple(tokens[start_idx:start_idx+order-1])\n",
        "\n",
        "def generate_text(context_counts, order, length, seed_text=''):\n",
        "    context = choose_start_context(train_tokens, order, seed_text)\n",
        "    out = list(context)\n",
        "    for _ in range(length):\n",
        "        counter = context_counts.get(context)\n",
        "        if not counter:\n",
        "            context = random.choice(list(context_counts.keys()))\n",
        "            counter = context_counts[context]\n",
        "        nxt = pick_next(counter)\n",
        "        out.append(nxt)\n",
        "        context = tuple(out[-(order-1):])\n",
        "    if LEVEL == 'word':\n",
        "        text = \" \".join(out)\n",
        "        text = re.sub(r\"\\s+([.!?,;:])\", r\"\\1\", text)\n",
        "        return text\n",
        "    return \"\".join(out)\n",
        "\n",
        "generated = generate_text(context_counts, ORDER, GENERATE_LEN, SEED_TEXT)\n",
        "print(\"üìù Generated Text:\\n\", generated)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NG7qUUIOvbwk",
        "outputId": "fb5c85ac-a3ad-45aa-aa73-f4aee62e19d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìù Generated Text:\n",
            " a curious student who loved to build models. \n",
            " they read books, collected stories, and stitched together patterns of words. \n",
            " markov chains, simple yet of convincingly other day words away and there a convincingly words often words follow other words, \n",
            " they read books, collected stories, and stitched together patterns of words. \n",
            " they read books, collected stories, and stitched together patterns of words. \n",
            " markov chains, simple yet away. a student words counting machine upon of one curious, yet models. \n",
            " one day, they discovered that by counting how often words follow other words, \n",
            " they read books, collected stories,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîπ Model Evaluation\n",
        "We evaluate with 3 metrics:\n",
        "- **Coverage** ‚Üí % of holdout contexts seen in training  \n",
        "- **Avg branching factor** ‚Üí Avg number of possible next tokens per context  \n",
        "- **Cross-Entropy** ‚Üí Average model surprise on holdout (lower = better)  \n"
      ],
      "metadata": {
        "id": "PdAvtXhko98j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def contexts_from(tokens, order):\n",
        "    for i in range(len(tokens) - order + 1):\n",
        "        yield tuple(tokens[i:i+order-1]), tokens[i+order-1]\n",
        "\n",
        "holdout_pairs = list(contexts_from(holdout_tokens, ORDER))\n",
        "seen_contexts = set(context_counts.keys())\n",
        "\n",
        "coverage = sum(1 for ctx, _ in holdout_pairs if ctx in seen_contexts) / len(holdout_pairs) if holdout_pairs else float('nan')\n",
        "avg_branching = sum(len(counter) for counter in context_counts.values()) / len(context_counts) if context_counts else float('nan')\n",
        "\n",
        "def cross_entropy_bits(context_counts, pairs):\n",
        "    total_bits = 0.0\n",
        "    for ctx, nxt in pairs:\n",
        "        counter = context_counts.get(ctx)\n",
        "        if not counter:\n",
        "            p = 1e-8\n",
        "        else:\n",
        "            V = len(counter)\n",
        "            p = (counter.get(nxt, 0) + 1) / (sum(counter.values()) + V)\n",
        "        total_bits += -math.log2(p)\n",
        "    return total_bits / len(pairs) if pairs else float('nan')\n",
        "\n",
        "ce = cross_entropy_bits(context_counts, holdout_pairs)\n",
        "\n",
        "print(f\"üìà Coverage: {coverage:.3f}\")\n",
        "print(f\"üìà Avg branching factor: {avg_branching:.3f}\")\n",
        "print(f\"üìà Cross-entropy: {ce:.3f} bits/token\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6dInommvwrx",
        "outputId": "da334e37-38cb-40b3-bbec-25db36f5dc85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìà Coverage: 0.000\n",
            "üìà Avg branching factor: 1.046\n",
            "üìà Cross-entropy: 26.575 bits/token\n"
          ]
        }
      ]
    }
  ]
}